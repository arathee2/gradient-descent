# gradient-descent
Implementation of gradient descent from scratch. The aim of this code was to learn how gradient descent works.

# How to run
The code is simple to run. You can either copy-paste it in a jupyter notebook and run, or run the file directly.

There are three separate code blocks. Each block has a different purpose as listed below:
1. In the first code block, the loss function is a single-input single-output function. The input is a scalar.
2. In the second code block, the loss function is a multi-input single-output function. The inputs are scalars.
3. In the third code block, the loss function is a single-input single-output function. The input is a vector. This is more practical implementation because it is used in neural networks.